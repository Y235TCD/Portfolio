# Portfolio
Collection de mes projets acadÃ©miques et professionnels, illustrant mes compÃ©tences en Ã©conomie, finance et data


# ğŸ“ˆ Analyse des Rendements Boursiers

Projet d'analyse quantitative des rendements boursiers du S&P 500 et d'actifs franÃ§ais (Orange, Danone, CAC40) en R.

## ğŸ“‹ Description

Ce projet propose une analyse complÃ¨te des rendements financiers, incluant :
- Analyse des rendements quotidiens du S&P 500
- Ã‰tude de l'autocorrÃ©lation des rendements
- Comparaison multi-actifs sur le marchÃ© franÃ§ais
- Calcul de mÃ©triques de performance (ratio de Sharpe, skewness)
- Optimisation de portefeuille binaire

## ğŸ”§ PrÃ©requis

- R (version â‰¥ 4.0.0 recommandÃ©e)
- RStudio (optionnel mais recommandÃ©)

### Packages nÃ©cessaires

```r
install.packages(c("quantmod", "moments", "ggplot2"))
```

## ğŸ“¦ Installation

1. Clonez ce dÃ©pÃ´t :
```bash
git clone https://github.com/votre-username/analyse-rendements-boursiers.git
cd analyse-rendements-boursiers
```

2. Ouvrez le fichier `Finance.R` dans RStudio

3. ExÃ©cutez les premiÃ¨res lignes pour installer les dÃ©pendances :
```r
library(quantmod)
library(moments)
library(ggplot2)
```

## ğŸš€ Utilisation

Le script est organisÃ© en sections numÃ©rotÃ©es :

### 1. Configuration de la pÃ©riode d'Ã©tude
```r
time_period <- 5  # PÃ©riode en annÃ©es
```

### 2. Analyse du S&P 500
- RÃ©cupÃ©ration des donnÃ©es via Yahoo Finance
- Calcul des rendements logarithmiques quotidiens
- Visualisation avec ggplot2
- RÃ©gression (t vs t-1) pour dÃ©tecter l'autocorrÃ©lation

### 3. Analyse multi-actifs
Actifs analysÃ©s :
- **ORA.PA** : Orange
- **BN.PA** : Danone  
- **C40.PA** : CAC 40

### 4. MÃ©triques calculÃ©es
- Rendements moyens mensuels et annuels
- VolatilitÃ© (Ã©cart-type)
- Ratio de Sharpe (taux sans risque : 3%)
- Skewness (asymÃ©trie de la distribution)

### 5. Optimisation de portefeuille
Calcul du risque d'un portefeuille binaire en fonction de la pondÃ©ration des actifs.

## ğŸ“Š Visualisations gÃ©nÃ©rÃ©es

Le script produit plusieurs graphiques :
- Rendements logarithmiques quotidiens du S&P 500 (colorÃ©s selon le signe)
- Nuages de points avec droite de rÃ©gression
- Prix normalisÃ©s (base 100) des actifs franÃ§ais
- Histogrammes des rendements mensuels
- Relation risque/poids dans un portefeuille

## ğŸ“ Fonctions principales

### `get_daily_stock_return.fct()`
RÃ©cupÃ¨re les rendements logarithmiques quotidiens d'un actif.

```r
sp500_return <- get_daily_stock_return.fct("^GSPC", start_date, end_date)
```

### `get_daily_stock_price.fct()`
RÃ©cupÃ¨re les prix ajustÃ©s d'un actif.

```r
ora_price <- get_daily_stock_price.fct("ORA.PA", start_date, end_date)
```

### `portfolio_sd.fct()`
Calcule l'Ã©cart-type d'un portefeuille binaire.

```r
risk <- portfolio_sd.fct(stock1, stock2, weight = 0.5)
```

## ğŸ“ˆ Exemple de rÃ©sultats

Les mÃ©triques typiques obtenues incluent :
- **Rendements annualisÃ©s** : comparaison de performance entre actifs
- **Ratio de Sharpe** : mesure du rendement ajustÃ© au risque
- **CorrÃ©lations** : relations entre les diffÃ©rents actifs
- **Skewness** : identification des asymÃ©tries de distribution

## ğŸ” MÃ©thodologie

### Rendements logarithmiques
Les rendements sont calculÃ©s en logarithme :
```
r_t = ln(P_t / P_{t-1})
```

### Normalisation
Les prix sont normalisÃ©s en base 100 pour faciliter la comparaison :
```
Prix_normalisÃ© = 100 Ã— (Prix / Prix_initial)
```

### Annualisation
- Rendement annuel : `(1 + r_mensuel)^12 - 1`
- VolatilitÃ© annuelle : `Ïƒ_mensuel Ã— âˆš12`

## âš™ï¸ Configuration

Modifiez ces paramÃ¨tres au dÃ©but du script selon vos besoins :

```r
time_period <- 5              # PÃ©riode d'analyse (annÃ©es)
risk_free_rate <- 3           # Taux sans risque (%)
bins.vec <- seq(-0.225, 0.2, by=0.025)  # Histogrammes
```

## ğŸ“ Notes importantes

- Les donnÃ©es proviennent de Yahoo Finance via le package `quantmod`
- Une connexion internet est requise pour tÃ©lÃ©charger les donnÃ©es
- Les tickers doivent Ãªtre valides sur Yahoo Finance
- Le script filtre les valeurs aberrantes (Â±5%) pour certaines analyses

## ğŸ¤ Contribution

Les contributions sont les bienvenues ! N'hÃ©sitez pas Ã  :
1. Forker le projet
2. CrÃ©er une branche (`git checkout -b feature/amelioration`)
3. Commiter vos changements (`git commit -m 'Ajout fonctionnalitÃ©'`)
4. Pusher vers la branche (`git push origin feature/amelioration`)
5. Ouvrir une Pull Request


## ğŸ“§ Contact

Pour toute question ou suggestion, n'hÃ©sitez pas Ã  ouvrir une issue sur GitHub.

## ğŸ™ Remerciements

- Package `quantmod` pour l'accÃ¨s aux donnÃ©es financiÃ¨res
- Package `ggplot2` pour les visualisations avancÃ©es
- Yahoo Finance pour les donnÃ©es de marchÃ©

---
â­ Si ce projet vous a Ã©tÃ© utile, n'hÃ©sitez pas Ã  lui donner une Ã©toile !

# ğŸ’³ DÃ©tection de Fraude par Carte de CrÃ©dit

Projet de Machine Learning pour la dÃ©tection automatique de transactions frauduleuses utilisant le dataset Kaggle Credit Card Fraud 2023.

[![Python](https://img.shields.io/badge/Python-3.8+-blue.svg)](https://www.python.org/)
[![Scikit-learn](https://img.shields.io/badge/scikit--learn-ML-orange.svg)](https://scikit-learn.org/)
[![Jupyter](https://img.shields.io/badge/Jupyter-Notebook-F37626.svg)](https://jupyter.org/)

## ğŸ“‹ Table des matiÃ¨res

- [Description](#-description)
- [Dataset](#-dataset)
- [Installation](#-installation)
- [Structure du projet](#-structure-du-projet)
- [MÃ©thodologie](#-mÃ©thodologie)
- [RÃ©sultats](#-rÃ©sultats)
- [Technologies utilisÃ©es](#-technologies-utilisÃ©es)
- [Utilisation](#-utilisation)


## ğŸ¯ Description

Ce projet implÃ©mente un systÃ¨me de dÃ©tection de fraude bancaire utilisant des techniques de Machine Learning. L'objectif est d'identifier automatiquement les transactions frauduleuses parmi un grand volume de transactions lÃ©gitimes, un problÃ¨me classique de classification dÃ©sÃ©quilibrÃ©e.

### ProblÃ©matique

- **DÃ©sÃ©quilibre des classes** : Les fraudes reprÃ©sentent moins de 1% des transactions
- **CoÃ»t asymÃ©trique** : Une fraude non dÃ©tectÃ©e coÃ»te plus cher qu'une fausse alerte
- **Features anonymisÃ©es** : Variables transformÃ©es par PCA (V1-V28) pour protÃ©ger la confidentialitÃ©

## ğŸ“Š Dataset

**Source** : Kaggle - Credit Card Fraud Detection 2023

### CaractÃ©ristiques
- **Transactions totales** : ~550,000
- **Features** : 31 colonnes
  - `Time` : Secondes Ã©coulÃ©es depuis la premiÃ¨re transaction
  - `V1-V28` : Composantes principales (PCA) anonymisÃ©es
  - `Amount` : Montant de la transaction
  - `Class` : Variable cible (0 = Normal, 1 = Fraude)

### DÃ©sÃ©quilibre des classes
- **Classe 0 (Normal)** : ~99.83%
- **Classe 1 (Fraude)** : ~0.17%
- **Ratio** : Environ 1 fraude pour 578 transactions normales

## ğŸ”§ Installation

### PrÃ©requis

- Python 3.8 ou supÃ©rieur
- Jupyter Notebook ou JupyterLab

### DÃ©pendances

Installez les packages nÃ©cessaires :

```bash
pip install pandas numpy matplotlib seaborn scikit-learn imbalanced-learn joblib
```

Ou utilisez le fichier requirements.txt :

```bash
pip install -r requirements.txt
```

### Fichier requirements.txt

```
pandas>=1.3.0
numpy>=1.21.0
matplotlib>=3.4.0
seaborn>=0.11.0
scikit-learn>=1.0.0
imbalanced-learn>=0.9.0
joblib>=1.0.0
```

## ğŸ“ Structure du projet

```
credit-card-fraud-detection/
â”‚
â”œâ”€â”€ Projet_Kaggle_Credit_Crad_Fraude.ipynb   # Notebook principal
â”œâ”€â”€ creditcard_2023.csv                       # Dataset (Ã  tÃ©lÃ©charger)
â”œâ”€â”€ README.md                                 # Ce fichier
â”œâ”€â”€ requirements.txt                          # DÃ©pendances Python
â””â”€â”€ models/                                   # ModÃ¨les sauvegardÃ©s (optionnel)
    â””â”€â”€ logistic_regression_model.pkl
```

## ğŸ”¬ MÃ©thodologie

### 1ï¸âƒ£ Chargement et Visualisation des DonnÃ©es

- Importation du dataset
- VÃ©rification de l'intÃ©gritÃ© (valeurs manquantes, types de donnÃ©es)
- Analyse de la distribution des classes

### 2ï¸âƒ£ Analyse Exploratoire (EDA)

#### Distribution des transactions
```python
# Classe 0 : 99.83% | Classe 1 : 0.17%
```

#### Analyse des corrÃ©lations
- **Variables positivement corrÃ©lÃ©es avec la fraude** : V4, V11, V2
- **Variables nÃ©gativement corrÃ©lÃ©es avec la fraude** : V14, V17, V10, V12

#### Analyse des montants
- Transactions normales : montants variables
- Transactions frauduleuses : tendance vers des montants spÃ©cifiques

### 3ï¸âƒ£ PrÃ©paration des DonnÃ©es

#### SÃ©lection des features importantes
```python
important_features = ['V14', 'V4', 'V10', 'V11', 'V12', 
                      'V17', 'V2', 'V3', 'V9', 'V7', 'Amount']
```

#### Standardisation
- Normalisation de la variable `Amount` avec StandardScaler
- Mise Ã  l'Ã©chelle pour cohÃ©rence avec les variables V1-V28

#### Split des donnÃ©es
- **Train set** : 80% des donnÃ©es
- **Test set** : 20% des donnÃ©es
- **Stratification** : Conservation du ratio fraude/normal dans chaque ensemble

### 4ï¸âƒ£ ModÃ©lisation

#### RÃ©gression Logistique

**Configuration** :
```python
LogisticRegression(max_iter=1000)
```

**EntraÃ®nement** :
- Temps d'entraÃ®nement : ~2 secondes
- Validation croisÃ©e Ã  5 folds

## ğŸ“ˆ RÃ©sultats

### MÃ©triques de Performance

| MÃ©trique | Score | InterprÃ©tation |
|----------|-------|----------------|
| **Accuracy** | ~0.99 | Taux de bonnes prÃ©dictions global |
| **Precision** | Variable | FiabilitÃ© des alertes de fraude |
| **Recall** | Variable | CapacitÃ© Ã  dÃ©tecter les fraudes |
| **F1-Score** | Variable | Ã‰quilibre prÃ©cision/rappel |
| **AUC-ROC** | ~0.95+ | Excellente capacitÃ© discriminante |

### Matrice de Confusion

```
                  PrÃ©diction
                Normal  Fraude
RÃ©alitÃ© Normal    TN      FP
        Fraude    FN      TP
```

- **TN (True Negative)** : Transactions normales correctement identifiÃ©es
- **FP (False Positive)** : Fausses alertes (â— coÃ»teuses en service client)
- **FN (False Negative)** : Fraudes manquÃ©es (ğŸš¨ critiques !)
- **TP (True Positive)** : Fraudes dÃ©tectÃ©es

### Courbe ROC

L'AUC-ROC Ã©levÃ©e (~0.95) indique que le modÃ¨le distingue trÃ¨s bien les fraudes des transactions normales.

### Validation CroisÃ©e

- **StabilitÃ©** : Faible variance entre les folds
- **Robustesse** : Performance cohÃ©rente sur diffÃ©rents sous-ensembles

## ğŸ› ï¸ Technologies utilisÃ©es

### BibliothÃ¨ques Python

- **pandas** : Manipulation de donnÃ©es
- **numpy** : Calculs numÃ©riques
- **matplotlib & seaborn** : Visualisations
- **scikit-learn** : ModÃ¨les ML et mÃ©triques
- **imbalanced-learn** : Gestion du dÃ©sÃ©quilibre de classes (SMOTE, RandomUnderSampler)
- **joblib** : Sauvegarde des modÃ¨les

### Algorithmes

- âœ… **RÃ©gression Logistique** (implÃ©mentÃ©)

## ğŸ’» Utilisation

### 1. TÃ©lÃ©charger le dataset

TÃ©lÃ©chargez le dataset depuis [Kaggle](https://www.kaggle.com/datasets/nelgiriyewithana/credit-card-fraud-detection-dataset-2023) et placez-le dans le dossier du projet.

### 2. Ouvrir le notebook

```bash
jupyter notebook Projet_Kaggle_Credit_Crad_Fraude.ipynb
```

### 3. ExÃ©cuter les cellules

ExÃ©cutez les cellules dans l'ordre pour :
1. Charger les donnÃ©es
2. Effectuer l'analyse exploratoire
3. EntraÃ®ner le modÃ¨le
4. Ã‰valuer les performances

### 4. PrÃ©dire de nouvelles transactions

```python
# Exemple de prÃ©diction
new_transaction = [[...]]  # Features de la transaction
prediction = model_LR.predict(new_transaction)
probability = model_LR.predict_proba(new_transaction)[:, 1]

if prediction[0] == 1:
    print(f"âš ï¸ FRAUDE DÃ‰TECTÃ‰E (ProbabilitÃ©: {probability[0]:.2%})")
else:
    print(f"âœ… Transaction normale (ProbabilitÃ© fraude: {probability[0]:.2%})")
```

## ğŸ“Š Visualisations clÃ©s

Le notebook gÃ©nÃ¨re plusieurs visualisations :

1. **Distribution des classes** : Histogramme montrant le dÃ©sÃ©quilibre
2. **Matrice de corrÃ©lation** : Heatmap des corrÃ©lations avec Class
3. **Boxplots** : Distribution des variables V4 et V14 par classe
4. **Matrice de confusion** : Performance du modÃ¨le
5. **Courbe ROC** : CapacitÃ© discriminante

## ğŸ“ Apprentissages clÃ©s

### Gestion du dÃ©sÃ©quilibre
- L'accuracy seule est trompeuse sur donnÃ©es dÃ©sÃ©quilibrÃ©es
- Le recall est crucial pour minimiser les fraudes manquÃ©es
- Le F1-score offre un bon Ã©quilibre

### Importance des features
- Les variables PCA les plus corrÃ©lÃ©es sont les plus prÃ©dictives
- La standardisation de Amount amÃ©liore les performances
- La rÃ©duction dimensionnelle peut amÃ©liorer la gÃ©nÃ©ralisation

### Validation
- La validation croisÃ©e garantit la robustesse
- Le test set doit Ãªtre stratifiÃ©
- L'AUC-ROC est une mÃ©trique robuste au dÃ©sÃ©quilibre

## ğŸ¤ Contribution

Les contributions sont les bienvenues ! Pour contribuer :

1. Forkez le projet
2. CrÃ©ez une branche (`git checkout -b feature/amelioration`)
3. Committez vos changements (`git commit -m 'Ajout: nouvelle fonctionnalitÃ©'`)
4. Pushez vers la branche (`git push origin feature/amelioration`)
5. Ouvrez une Pull Request

### IdÃ©es de contribution
- ImplÃ©menter d'autres algorithmes
- AmÃ©liorer les visualisations
- Ajouter des tests unitaires
- Optimiser les hyperparamÃ¨tres
- CrÃ©er un dashboard interactif


## ğŸ“š Ressources

- [Dataset Kaggle](https://www.kaggle.com/datasets/nelgiriyewithana/credit-card-fraud-detection-dataset-2023)
- [Scikit-learn Documentation](https://scikit-learn.org/stable/)
- [Imbalanced-learn Guide](https://imbalanced-learn.org/stable/)
- [Paper: SMOTE](https://arxiv.org/abs/1106.1813)

## ğŸ“§ Contact

Pour toute question ou suggestion :
- Ouvrez une **issue** sur GitHub
- Contactez-moi via youssoufsalehhaliki@gmail.com

## ğŸ™ Remerciements

- Kaggle pour le dataset
- La communautÃ© scikit-learn
- Les contributeurs d'imbalanced-learn

---

â­ **Si ce projet vous a Ã©tÃ© utile, n'hÃ©sitez pas Ã  lui donner une Ã©toile !**

ğŸ” **Note de sÃ©curitÃ©** : Ce projet est Ã  des fins Ã©ducatives. Pour un dÃ©ploiement en production, des mesures de sÃ©curitÃ© et de confidentialitÃ© supplÃ©mentaires sont nÃ©cessaires.
